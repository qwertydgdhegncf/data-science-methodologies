{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Sb9j9_01Ey",
        "outputId": "46cd7d7b-6291-44de-920d-b804bbfb7c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (395, 33)\n",
            "Target distribution summary:\n",
            "count    395.000000\n",
            "mean      10.415190\n",
            "std        4.581443\n",
            "min        0.000000\n",
            "25%        8.000000\n",
            "50%       11.000000\n",
            "75%       14.000000\n",
            "max       20.000000\n",
            "Name: G3, dtype: float64\n",
            "\n",
            "Top correlations with G3:\n",
            "G3             1.000000\n",
            "G2             0.904868\n",
            "G1             0.801468\n",
            "Medu           0.217147\n",
            "higher_yes     0.182465\n",
            "Fedu           0.152457\n",
            "romantic_no    0.129970\n",
            "Mjob_health    0.116158\n",
            "address_U      0.105756\n",
            "sex_M          0.103456\n",
            "Name: G3, dtype: float64\n",
            "rf mean CV R2: 0.8843\n",
            "xgb mean CV R2: nan\n",
            "\n",
            "Best model: rf | Mean CV R2: 0.8843\n",
            "\n",
            "=== FINAL MODEL PERFORMANCE ===\n",
            "Selected model: rf\n",
            "R²: 0.8058 | MAE: 1.1942\n",
            "Interpretation: RandomForest offered stable generalization and feature robustness.\n",
            "\n",
            "Artifacts saved successfully to artifacts/ folder.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('rf', np.float64(0.8843214956669773))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# =========================================================\n",
        "# SEMMA: Sample, Explore, Modify, Model, Assess\n",
        "# Dataset: UCI Student Performance (Portuguese course)\n",
        "# Goal: Predict final grade (G3)\n",
        "# =========================================================\n",
        "\n",
        "import os, urllib.request, zipfile, io, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# === SETUP ===\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"artifacts/figs\", exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# === SAMPLE PHASE ===\n",
        "# =========================================================\n",
        "# Obtain UCI Student Performance dataset (Portuguese course)\n",
        "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\"\n",
        "z = io.BytesIO(urllib.request.urlopen(URL).read())\n",
        "zipfile.ZipFile(z).extractall(\"data\")\n",
        "df = pd.read_csv(\"data/student-mat.csv\", sep=\";\")\n",
        "\n",
        "# Define target and predictors\n",
        "target = \"G3\"\n",
        "y = df[target].values\n",
        "X = df.drop(columns=[target])\n",
        "\n",
        "print(\"Data shape:\", df.shape)\n",
        "print(\"Target distribution summary:\")\n",
        "print(df[target].describe())\n",
        "\n",
        "# =========================================================\n",
        "# === EXPLORE PHASE ===\n",
        "# =========================================================\n",
        "# Visualize correlations\n",
        "corr = pd.get_dummies(df).corr()[\"G3\"].sort_values(ascending=False)\n",
        "print(\"\\nTop correlations with G3:\")\n",
        "print(corr.head(10))\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(pd.get_dummies(df).corr()[[\"G3\"]].sort_values(\"G3\", ascending=False).head(20),\n",
        "            annot=False, cmap=\"coolwarm\")\n",
        "plt.title(\"Top correlations with G3\")\n",
        "plt.savefig(\"artifacts/figs/corr_semma.png\")\n",
        "plt.close()\n",
        "\n",
        "# =========================================================\n",
        "# === MODIFY PHASE ===\n",
        "# =========================================================\n",
        "# Feature engineering\n",
        "X[\"failures_bin\"] = (df[\"failures\"] > 0).astype(int)\n",
        "X[\"studytime_cat\"] = df[\"studytime\"].astype(\"category\")\n",
        "\n",
        "# Define numeric and categorical feature groups\n",
        "num_cols = X.select_dtypes(include=\"number\").columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
        "\n",
        "# Transformation pipelines\n",
        "num_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"sc\", StandardScaler())\n",
        "])\n",
        "cat_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", num_pipe, num_cols),\n",
        "    (\"cat\", cat_pipe, cat_cols)\n",
        "])\n",
        "\n",
        "# =========================================================\n",
        "# === MODEL PHASE ===\n",
        "# =========================================================\n",
        "models = {\n",
        "    \"rf\": RandomForestRegressor(n_estimators=400, random_state=42),\n",
        "    \"xgb\": XGBRegressor(\n",
        "        n_estimators=400, learning_rate=0.05, max_depth=5,\n",
        "        subsample=0.9, colsample_bytree=0.9, random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "best_name, best_pipe, best_score = None, None, -999\n",
        "# StratifiedKFold based on grade bins for balanced folds\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(\n",
        "    pd.cut(y_train, bins=5, labels=False), np.zeros_like(y_train)\n",
        ")\n",
        "\n",
        "for name, est in models.items():\n",
        "    pipe = Pipeline([(\"pre\", pre), (\"model\", est)])\n",
        "    scores = []\n",
        "    for tr_idx, va_idx in cv:\n",
        "        pipe.fit(X_train.iloc[tr_idx], y_train[tr_idx])\n",
        "        pred = pipe.predict(X_train.iloc[va_idx])\n",
        "        scores.append(r2_score(y_train[va_idx], pred))\n",
        "    mean_r2 = np.mean(scores)\n",
        "    print(f\"{name} mean CV R2: {mean_r2:.4f}\")\n",
        "    if mean_r2 > best_score:\n",
        "        best_name, best_pipe, best_score = name, pipe, mean_r2\n",
        "\n",
        "print(\"\\nBest model:\", best_name, \"| Mean CV R2:\", round(best_score, 4))\n",
        "\n",
        "# =========================================================\n",
        "# === ASSESS PHASE ===\n",
        "# =========================================================\n",
        "best_pipe.fit(X_train, y_train)\n",
        "pred = best_pipe.predict(X_test)\n",
        "r2 = r2_score(y_test, pred)\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "\n",
        "print(\"\\n=== FINAL MODEL PERFORMANCE ===\")\n",
        "print(f\"Selected model: {best_name}\")\n",
        "print(f\"R²: {r2:.4f} | MAE: {mae:.4f}\")\n",
        "if best_name == \"xgb\":\n",
        "    print(\"Interpretation: XGBoost captured nonlinear grade predictors (failures, studytime, absences).\")\n",
        "else:\n",
        "    print(\"Interpretation: RandomForest offered stable generalization and feature robustness.\")\n",
        "\n",
        "# Save artifacts\n",
        "import joblib, json\n",
        "joblib.dump(best_pipe, \"artifacts/model_reg.pkl\")\n",
        "with open(\"artifacts/metrics.json\", \"w\") as f:\n",
        "    json.dump({\"r2\": float(r2), \"mae\": float(mae), \"model\": best_name}, f, indent=2)\n",
        "print(\"\\nArtifacts saved successfully to artifacts/ folder.\")\n",
        "\n",
        "best_name, best_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoPK7Sf31Iqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}