{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Z_e-6I1xmM",
        "outputId": "2a8fb566-cc27-4118-97f7-0659c6ca1476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised AUC: 0.970987885165321\n",
            "Average Precision: 0.7244601740257454\n",
            "IForest AUC (inference only): 0.9540032142570027\n",
            "Saved artifacts/fraud_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- KDD: Selection, Preprocessing, Transformation, Data Mining, Interpretation ---\n",
        "import os, urllib.request, zipfile, io, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "os.makedirs(\"artifacts\", exist_ok=True); os.makedirs(\"data\", exist_ok=True); os.makedirs(\"artifacts/figs\", exist_ok=True)\n",
        "\n",
        "# SELECTION: Kaggle credit card fraud (European cardholders, PCA'ed features)\n",
        "URL = \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
        "path = \"data/creditcard.csv\"\n",
        "if not os.path.exists(path):\n",
        "    urllib.request.urlretrieve(URL, path)\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# PREPROCESSING\n",
        "y = df[\"Class\"].values\n",
        "X = df.drop(columns=[\"Class\"])\n",
        "\n",
        "# TRANSFORMATION\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# DATA MINING (two angles):\n",
        "# 1) Supervised (if labels available): handle imbalance with SMOTE + Logistic Regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_tr, y_tr = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "clf = LogisticRegression(max_iter=500, class_weight=None)\n",
        "clf.fit(X_tr, y_tr)\n",
        "proba = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"Supervised AUC:\", roc_auc_score(y_test, proba))\n",
        "print(\"Average Precision:\", average_precision_score(y_test, proba))\n",
        "\n",
        "# 2) Unsupervised anomaly detection (when labels scarce)\n",
        "iso = IsolationForest(n_estimators=400, contamination=0.0015, random_state=42)\n",
        "iso.fit(X_train)\n",
        "anom_score = -iso.decision_function(X_test)\n",
        "print(\"IForest AUC (inference only):\", roc_auc_score(y_test, anom_score))\n",
        "\n",
        "# INTERPRETATION\n",
        "from sklearn.inspection import permutation_importance\n",
        "perm = permutation_importance(clf, X_test, y_test, n_repeats=5, random_state=42, scoring=\"average_precision\")\n",
        "imp = pd.Series(perm.importances_mean).sort_values(ascending=False)[:15]\n",
        "plt.figure(figsize=(6,5)); imp[::-1].plot(kind=\"barh\"); plt.title(\"Permutation importance (top15)\"); plt.tight_layout()\n",
        "plt.savefig(\"artifacts/figs/importance_kdd.png\"); plt.close()\n",
        "\n",
        "# Save artifacts\n",
        "import joblib, json\n",
        "joblib.dump({\"scaler\": scaler, \"clf\": clf}, \"artifacts/fraud_model.pkl\")\n",
        "with open(\"artifacts/metrics.json\",\"w\") as f: json.dump({\n",
        "    \"auc_supervised\": float(roc_auc_score(y_test, proba)),\n",
        "    \"ap_supervised\": float(average_precision_score(y_test, proba))\n",
        "}, f, indent=2)\n",
        "print(\"Saved artifacts/fraud_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkQantbU14z9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}