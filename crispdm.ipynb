{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CGkoxrBpyRzs"
      },
      "outputs": [],
      "source": [
        "# --- CRISP-DM 1/6: BUSINESS UNDERSTANDING ---\n",
        "\"\"\"\n",
        "Goal: Predict customer churn for a telco to reduce attrition.\n",
        "Primary metric: Recall (identify churners) with balanced Precision → F1.\n",
        "Secondary: Business-friendly explanation (feature importances, SHAP-like via permutation).\n",
        "Deployment target: A saved sklearn Pipeline (model.pkl) + threshold from validation.\n",
        "\"\"\"\n",
        "\n",
        "# --- Setup ---\n",
        "import os, json, zipfile, urllib.request, io, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support, RocCurveDisplay\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"artifacts/figs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CRISP-DM 2/6: DATA UNDERSTANDING ---\n",
        "# Working link for IBM Telco Customer Churn dataset\n",
        "import urllib.request, os, pandas as pd\n",
        "\n",
        "URL = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "csv_path = \"data/telco_churn.csv\"\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    urllib.request.urlretrieve(URL, csv_path)\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.head(3))\n",
        "print(df.shape, df['Churn'].value_counts(normalize=True))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLNxWBs7ymCC",
        "outputId": "52c59464-dad0-4023-d392-eb4ef8ae29c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
            "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
            "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
            "\n",
            "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
            "0  No phone service             DSL             No  ...               No   \n",
            "1                No             DSL            Yes  ...              Yes   \n",
            "2                No             DSL            Yes  ...               No   \n",
            "\n",
            "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
            "0          No          No              No  Month-to-month              Yes   \n",
            "1          No          No              No        One year               No   \n",
            "2          No          No              No  Month-to-month              Yes   \n",
            "\n",
            "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
            "0  Electronic check          29.85         29.85    No  \n",
            "1      Mailed check          56.95        1889.5    No  \n",
            "2      Mailed check          53.85        108.15   Yes  \n",
            "\n",
            "[3 rows x 21 columns]\n",
            "(7043, 21) Churn\n",
            "No     0.73463\n",
            "Yes    0.26537\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CRISP-DM 3/6: DATA PREPARATION ---\n",
        "target = 'Churn'\n",
        "y = df[target].map({'Yes':1,'No':0}).values\n",
        "X = df.drop(columns=[target,'customerID'])\n",
        "\n",
        "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=['number']).columns.tolist()\n",
        "\n",
        "numeric = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "categorical = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric, num_cols),\n",
        "        (\"cat\", categorical, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# train/validation/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "4IiykC-jyt4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CRISP-DM 4/6: MODELING ---\n",
        "models = {\n",
        "    \"logreg\": LogisticRegression(max_iter=200, n_jobs=None),\n",
        "    \"rf\": RandomForestClassifier(n_estimators=400, random_state=42, class_weight=\"balanced\"),\n",
        "    \"xgb\": XGBClassifier(\n",
        "        n_estimators=400, max_depth=5, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9,\n",
        "        eval_metric=\"logloss\", random_state=42, scale_pos_weight=float((y_train==0).sum()/(y_train==1).sum())\n",
        "    )\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_results = {}\n",
        "for name, est in models.items():\n",
        "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", est)])\n",
        "    auc = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
        "    ap = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"average_precision\")\n",
        "    cv_results[name] = {\"roc_auc_mean\": float(auc.mean()), \"ap_mean\": float(ap.mean())}\n",
        "cv_results\n",
        "# pick best by Average Precision (prioritizes recall on positives)\n",
        "best_name = max(cv_results, key=lambda k: cv_results[k][\"ap_mean\"])\n",
        "best_name, cv_results[best_name]\n",
        "\n",
        "# Fit best on train, choose threshold by maximizing F1 on validation (split from train)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
        "\n",
        "best_est = models[best_name]\n",
        "best_pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", best_est)])\n",
        "best_pipe.fit(X_tr, y_tr)\n",
        "\n",
        "val_proba = best_pipe.predict_proba(X_val)[:,1]\n",
        "thresholds = np.linspace(0.1, 0.9, 81)\n",
        "f1s = []\n",
        "for t in thresholds:\n",
        "    preds = (val_proba >= t).astype(int)\n",
        "    p,r,f,_ = precision_recall_fscore_support(y_val, preds, average=\"binary\", zero_division=0)\n",
        "    f1s.append(f)\n",
        "t_opt = float(thresholds[int(np.argmax(f1s))])\n",
        "t_opt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO9IZAa0zW6D",
        "outputId": "5bc7d17c-2db9-4646-fd61-f6f766bece02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CRISP-DM 5/6: EVALUATION ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    RocCurveDisplay,\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "import json\n",
        "import joblib\n",
        "\n",
        "# --- Evaluate model performance on test set ---\n",
        "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
        "test_pred = (test_proba >= t_opt).astype(int)\n",
        "\n",
        "print(f\"\\nClassification report @ threshold {t_opt:.2f}\")\n",
        "print(classification_report(y_test, test_pred, digits=3))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, test_proba))\n",
        "print(\"Average Precision:\", average_precision_score(y_test, test_proba))\n",
        "\n",
        "# --- ROC curve ---\n",
        "plt.figure()\n",
        "RocCurveDisplay.from_predictions(y_test, test_proba)\n",
        "plt.title(\"ROC Curve - Test Set\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"artifacts/figs/roc_test.png\")\n",
        "plt.close()\n",
        "\n",
        "# --- FIXED Permutation Importance (on dense transformed features) ---\n",
        "print(\"\\nComputing permutation importances correctly on transformed features...\")\n",
        "\n",
        "# Separate preprocessing and model\n",
        "prep = best_pipe.named_steps[\"prep\"]\n",
        "model = best_pipe.named_steps[\"model\"]\n",
        "\n",
        "# Transform test data and convert to dense array\n",
        "X_test_transformed = prep.transform(X_test)\n",
        "if hasattr(X_test_transformed, \"toarray\"):\n",
        "    X_test_transformed = X_test_transformed.toarray()\n",
        "\n",
        "# Get correct feature names from transformers\n",
        "cat_transformer = prep.named_transformers_[\"cat\"]\n",
        "cat_encoder = cat_transformer.named_steps[\"onehot\"]\n",
        "cat_feature_names = list(cat_encoder.get_feature_names_out(cat_cols))\n",
        "num_feature_names = list(num_cols)\n",
        "all_feature_names = num_feature_names + cat_feature_names\n",
        "\n",
        "# Compute permutation importance on model\n",
        "perm = permutation_importance(\n",
        "    model,\n",
        "    X_test_transformed,\n",
        "    y_test,\n",
        "    n_repeats=10,\n",
        "    random_state=42,\n",
        "    scoring=\"f1\"\n",
        ")\n",
        "\n",
        "# Create sorted importance dataframe\n",
        "imp = pd.Series(perm.importances_mean, index=all_feature_names).sort_values(ascending=False)[:20]\n",
        "\n",
        "# Plot top 20 important features\n",
        "plt.figure(figsize=(7, 6))\n",
        "imp[::-1].plot(kind=\"barh\")\n",
        "plt.title(\"Permutation Importance (Top 20 Features)\")\n",
        "plt.xlabel(\"Mean Importance (F1-based)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"artifacts/figs/perm_importance.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Permutation importance saved → artifacts/figs/perm_importance.png\")\n",
        "\n",
        "# --- Save evaluation metrics and model metadata ---\n",
        "metrics = {\n",
        "    \"cv_results\": cv_results,\n",
        "    \"chosen_model\": best_name,\n",
        "    \"threshold\": float(t_opt),\n",
        "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
        "    \"average_precision\": float(average_precision_score(y_test, test_proba))\n",
        "}\n",
        "\n",
        "with open(\"artifacts/metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "# Save model with preprocessing pipeline\n",
        "joblib.dump({\"pipeline\": best_pipe, \"threshold\": t_opt}, \"artifacts/model.pkl\")\n",
        "\n",
        "print(\"\\n✅ Evaluation complete.\")\n",
        "print(\"Artifacts saved:\")\n",
        "print(\" - artifacts/figs/roc_test.png\")\n",
        "print(\" - artifacts/figs/perm_importance.png\")\n",
        "print(\" - artifacts/metrics.json\")\n",
        "print(\" - artifacts/model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "aGyDuvBozcty",
        "outputId": "36037d7f-297f-49a7-a10c-7eac65a58baf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report @ threshold 0.35\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.879     0.793     0.834      1035\n",
            "           1      0.549     0.698     0.615       374\n",
            "\n",
            "    accuracy                          0.768      1409\n",
            "   macro avg      0.714     0.746     0.724      1409\n",
            "weighted avg      0.792     0.768     0.776      1409\n",
            "\n",
            "ROC AUC: 0.8419902348291095\n",
            "Average Precision: 0.6368106415326183\n",
            "\n",
            "Computing permutation importances correctly on transformed features...\n",
            "Permutation importance saved → artifacts/figs/perm_importance.png\n",
            "\n",
            "✅ Evaluation complete.\n",
            "Artifacts saved:\n",
            " - artifacts/figs/roc_test.png\n",
            " - artifacts/figs/perm_importance.png\n",
            " - artifacts/metrics.json\n",
            " - artifacts/model.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CRISP-DM 6/6: DEPLOYMENT ARTIFACT ---\n",
        "import joblib\n",
        "joblib.dump({\"pipeline\": best_pipe, \"threshold\": t_opt}, \"artifacts/model.pkl\")\n",
        "print(\"Saved artifacts/model.pkl and artifacts/metrics.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiS04Iim193D",
        "outputId": "3a26f57a-257e-48c8-9315-c2fc1e00c4e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifacts/model.pkl and artifacts/metrics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0n-vFPO854G8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}